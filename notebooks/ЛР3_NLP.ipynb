{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XE\\AppData\\Local\\Temp\\ipykernel_3788\\3478127182.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_en = pd.read_csv(r'C:\\Users\\XE\\Downloads\\1mcorpus\\corpus.en_ru.1m.en', encoding=\"utf-8\", names=[\"seq_en\"], sep='\\r\\n')\n",
      "C:\\Users\\XE\\AppData\\Local\\Temp\\ipykernel_3788\\3478127182.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df_ru = pd.read_csv(r'C:\\Users\\XE\\Downloads\\1mcorpus\\corpus.en_ru.1m.ru', encoding=\"utf-8\", names=[\"seq_ru\"], sep='\\r\\n')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_en = pd.read_csv(r'C:\\Users\\XE\\Downloads\\1mcorpus\\corpus.en_ru.1m.en', encoding=\"utf-8\", names=[\"seq_en\"], sep='\\r\\n')\n",
    "df_ru = pd.read_csv(r'C:\\Users\\XE\\Downloads\\1mcorpus\\corpus.en_ru.1m.ru', encoding=\"utf-8\", names=[\"seq_ru\"], sep='\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = df_en.sample(100000, random_state=0)\n",
    "df_ru = df_ru.sample(100000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en['seq_en'].to_csv(\"../datasets/NMT_en\")\n",
    "df_ru['seq_ru'].to_csv(\"../datasets/NMT_ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_en.join(df_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../datasets/NMT_en_ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import re\n",
    "from pymorphy3 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from razdel import tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from navec import Navec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torchdata\n",
    "from torchtext import transforms\n",
    "from torchdata import datapipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipe = datapipes.iter.IterableWrapper([\"../datasets/NMT_en_ru\"])\n",
    "data_pipe_ru = datapipes.iter.IterableWrapper([\"../datasets/NMT_ru\"])\n",
    "data_pipe_en = datapipes.iter.IterableWrapper([\"../datasets/NMT_en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipe = datapipes.iter.FileOpener(data_pipe, mode='r', encoding='utf-8')\n",
    "data_pipe_ru = datapipes.iter.FileOpener(data_pipe_ru, mode='r', encoding='utf-8')\n",
    "data_pipe_en = datapipes.iter.FileOpener(data_pipe_en, mode='r', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipe= data_pipe.parse_csv(skip_lines=0, as_tuple=True)\n",
    "data_pipe_ru = data_pipe_ru.parse_csv(skip_lines=0, as_tuple=True)\n",
    "data_pipe_en = data_pipe_en.parse_csv(skip_lines=0, as_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_en(data: str) -> list[str]:\n",
    "  data1 = re.sub(\"([.!?])\", \" \", str(data[1:]))\n",
    "  data2 = re.sub(\"[^\\s^\\w^']+\", \" \", data1)\n",
    "  data3 = word_tokenize(data2)\n",
    "  return data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_ru(data: str) -> list[str]:\n",
    "  data1 = re.sub(\"([.!?])\", \" \", str(data[1:]))\n",
    "  data2 = re.sub(\"[^\\s^\\w^']+\", \" \", data1)\n",
    "  data3 = tokenize(data2)\n",
    "  data4 = list(map(lambda x: x.text , data3))\n",
    "  return data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens_en(data_iter: datapipes.iter.IterDataPipe):\n",
    "  # итерируемся по набору данных\n",
    "  for example in data_iter:\n",
    "    yield tokenize_en(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens_ru(data_iter: datapipes.iter.IterDataPipe):\n",
    "  # итерируемся по набору данных\n",
    "  for example in data_iter:\n",
    "    yield tokenize_ru(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_en = build_vocab_from_iterator(\n",
    "    yield_tokens_en(data_pipe_en),\n",
    "    min_freq=1,\n",
    "    specials= ['<pad>', '<sos>', '<eos>', '<unk>'],\n",
    "    special_first=True\n",
    ")\n",
    "vocab_en.set_default_index(vocab_en['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_ru = build_vocab_from_iterator(\n",
    "    yield_tokens_ru(data_pipe_ru),\n",
    "    min_freq=1,\n",
    "    specials= ['<pad>', '<sos>', '<eos>', '<unk>'],\n",
    "    special_first=True\n",
    ")\n",
    "vocab_ru.set_default_index(vocab_ru['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_transform(vocab: torchtext.vocab.Vocab) -> transforms.Sequential:\n",
    "    text_tranform = transforms.Sequential(\n",
    "        transforms.VocabTransform(vocab=vocab),\n",
    "        transforms.AddToken(vocab['<sos>'], begin=True),\n",
    "        transforms.AddToken(vocab['<eos>'], begin=False)\n",
    "    )\n",
    "    return text_tranform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_vocab_transform(sample):\n",
    "    return (\n",
    "        vocab_transform(vocab_en)(tokenize_en(sample[1])),\n",
    "        vocab_transform(vocab_ru)(tokenize_ru(sample[2]))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipe = data_pipe.map(apply_vocab_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 3, 47, 1745, 46, 222, 5594, 2013, 8, 18, 14699, 254, 131, 1543, 12, 4, 205, 4474, 20772, 659, 10060, 2], [1, 3, 53, 31, 134, 7468, 2071, 24, 8812, 17056, 182925, 22, 1222, 6416, 119, 46027, 3030, 29, 81, 176964, 7175, 2])\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for sample in data_pipe:\n",
    "    if i == 1660:    \n",
    "        print(sample)\n",
    "        break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipe_new = []\n",
    "for sample in data_pipe:\n",
    "    data_pipe_new.append((torch.tensor(sample[0]), torch.tensor(sample[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "en_text_padded = pad_sequence([tupl[0] for tupl in data_pipe_new], True)\n",
    "ru_text_padded = pad_sequence([tupl[1] for tupl in data_pipe_new], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH_RU = 88\n",
    "MAX_LENGTH_EN = 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(en_text_padded, ru_text_padded, test_size=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XE\\AppData\\Local\\Temp\\ipykernel_3788\\3442895299.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ds = TensorDataset(X_train, torch.tensor(y_train).type(torch.int64))\n"
     ]
    }
   ],
   "source": [
    "ds = TensorDataset(X_train, torch.tensor(y_train).type(torch.int64))\n",
    "dl = DataLoader(ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device ( \"cuda:0\" if torch.cuda.is_available() else \"cpu\" )\n",
    "print ( device )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderNMT(nn.Module):\n",
    "    def __init__(self, input_size, embed_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderNMT, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embed_size)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderNMT(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, output_size):\n",
    "        super(DecoderNMT, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, embed_size)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(vocab_ru['SOS'])\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH_RU):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        #decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = self.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMT_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NMT_model, self).__init__()\n",
    "        self.encoder = EncoderNMT(len(vocab_en), 128, 128)\n",
    "        self.decoder = DecoderNMT(128, 128, len(vocab_ru))\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input)\n",
    "        decoder_outputs, _, _ = self.decoder(encoder_outputs, encoder_hidden, target)\n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "model = NMT_model()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\ML\\notebooks\\ЛР3_NLP.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/ML/notebooks/%D0%9B%D0%A03_NLP.ipynb#X64sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m decoder_outputs \u001b[39m=\u001b[39m model(x_b, y_b)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML/notebooks/%D0%9B%D0%A03_NLP.ipynb#X64sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m loss_value \u001b[39m=\u001b[39m loss(\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML/notebooks/%D0%9B%D0%A03_NLP.ipynb#X64sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     decoder_outputs\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, decoder_outputs\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)),\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML/notebooks/%D0%9B%D0%A03_NLP.ipynb#X64sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     y_b\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/ML/notebooks/%D0%9B%D0%A03_NLP.ipynb#X64sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m loss_value\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML/notebooks/%D0%9B%D0%A03_NLP.ipynb#X64sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML/notebooks/%D0%9B%D0%A03_NLP.ipynb#X64sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m#sys.stderr.write(f'Батч {batch + 1}/{len(dl)}, Значение функции потерь: {loss_value.item()}\\r')\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\XE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\XE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    batch = 0\n",
    "    for x_b, y_b in dl:\n",
    "        x_b = x_b.to(device)\n",
    "        y_b = y_b.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        batch+=1\n",
    "        decoder_outputs = model(x_b, y_b)\n",
    "\n",
    "        loss_value = loss(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            y_b.view(-1))\n",
    "        loss_value.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        #sys.stderr.write(f'Батч {batch + 1}/{len(dl)}, Значение функции потерь: {loss_value.item()}\\r')\n",
    "\n",
    "    print(f'Эпоха {epoch + 1}, Значение функции потерь: {loss_value.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
