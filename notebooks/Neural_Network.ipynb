{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit, logit\n",
    "from scipy import signal\n",
    "import tensorflow as tf\n",
    "\n",
    "def mse(y_test, y_pred):\n",
    "    return np.mean(np.power(y_test - y_pred, 2))/2\n",
    "\n",
    "def mse_deriv(y_test, y_pred):\n",
    "    return (y_pred - y_test) / len(y_test)\n",
    "\n",
    "def cross_entropy(y_test, y_pred):\n",
    "    return np.mean(-y_test * np.log(y_pred) - (1 - y_test) * np.log(1 - y_pred))\n",
    "\n",
    "def cross_entropy_deriv(y_test, y_pred):\n",
    "    return ((1 - y_test) / (1 - y_pred) - y_test / y_pred) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return expit(x)\n",
    "def tahn(x):\n",
    "    return np.tanh(x)    \n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "def linear(x):\n",
    "    return x\n",
    "def deriv_sigmoid(x):\n",
    "    return expit(x)*(1-expit(x))\n",
    "def deriv_tahn(x):\n",
    "    return -4/(np.exp(x)-np.exp(-x))**2\n",
    "def deriv_relu(x):\n",
    "    return (x>0)*1\n",
    "def deriv_linear(x):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation():\n",
    "    def __init__(self, activation_function_name):\n",
    "        self.activation_functions = dict(sigmoid=sigmoid,tahn=tahn,relu=relu, linear=linear)\n",
    "        self.deriv_functions = dict(sigmoid=deriv_sigmoid,tahn=deriv_tahn,relu=deriv_relu, linear=deriv_linear) \n",
    "        self.activation_function = self.activation_functions[activation_function_name]\n",
    "        self.activation_function_deriv = self.deriv_functions[activation_function_name]\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.output = self.activation_function(input)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output_err, learning_rate):\n",
    "        return np.multiply(output_err, self.activation_function_deriv(self.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense():\n",
    "    def __init__(self, input_shape, output_size):\n",
    "        self.weights = np.random.rand(output_size, input_shape)\n",
    "        self.b_coefs = np.random.rand(output_size, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return np.dot(self.weights, self.input) + self.b_coefs\n",
    "\n",
    "    def backward(self, output_err, learning_rate):\n",
    "        dW = np.dot(output_err, self.input.T)\n",
    "        backward_err = np.dot(self.weights.T, output_err)\n",
    "        self.weights -= learning_rate * dW\n",
    "        self.bias -= learning_rate * output_err\n",
    "        return backward_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolutional():\n",
    "    def __init__(self, input_shape, kernel_size, depth):\n",
    "        input_depth, input_height, input_width = input_shape\n",
    "        self.depth = depth\n",
    "        self.input_shape = input_shape\n",
    "        self.input_depth = input_depth\n",
    "        self.output_shape = (depth, input_height - kernel_size + 1, input_width - kernel_size + 1)\n",
    "        self.kernels_shape = (depth, input_depth, kernel_size, kernel_size)\n",
    "        self.kernels = np.random.rand(self.kernels_shape)\n",
    "        self.kernels_b = np.random.rand(self.output_shape)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        self.output = np.copy(self.kernels_b)\n",
    "        for i in range(self.depth):\n",
    "            for j in range(self.input_depth):\n",
    "                self.output[i] += signal.correlate2d(self.input[j], self.kernels[i, j], \"valid\")\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output_err, learning_rate):\n",
    "        kernels_err = np.zeros(self.kernels_shape)\n",
    "        input_err = np.zeros(self.input_shape)\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            for j in range(self.input_depth):\n",
    "                kernels_err[i, j] = signal.correlate2d(self.input[j], output_err[i], \"valid\")\n",
    "                input_err[j] += signal.convolve2d(output_err[i], self.kernels[i, j], \"full\")\n",
    "\n",
    "        self.kernels -= learning_rate * kernels_err\n",
    "        self.kernels_b -= learning_rate * output_err\n",
    "        return input_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape():\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    def forward(self, input):\n",
    "        return np.reshape(input, self.output_shape)\n",
    "\n",
    "    def backward(self, output_err, learning_rate):\n",
    "        return np.reshape(output_err, self.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss_functions = dict(mse = mse, cross_entropy = cross_entropy)\n",
    "        self.deriv_loss_functions = dict(mse = mse_deriv, cross_entropy = cross_entropy_deriv)\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    def compile(self, loss_function):\n",
    "        self.loss_function = self.loss_functions[loss_function]\n",
    "        self.loss_function_deriv = self.deriv_loss_functions[loss_function]\n",
    "    def fit(self, X_train, y_train, epochs, learning_rate, verbose=True):\n",
    "        for e in range(epochs):\n",
    "            error = 0\n",
    "            for x, y in zip(X_train, y_train):\n",
    "                output = x\n",
    "                for layer in self.layers:\n",
    "                     output = layer.forward(output)\n",
    "\n",
    "                error += self.loss_function(y, output)\n",
    "                err = self.loss_function_deriv(y, output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    err = layer.backward(err, learning_rate)\n",
    "\n",
    "            error /= len(X_train)\n",
    "            if verbose:\n",
    "                print(f\"{e + 1}/{epochs}, error={error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predobrab_data(X):\n",
    "    x_out, y_out = [], []\n",
    "    for batch, labels in X:\n",
    "        for img, label in zip(batch, labels):\n",
    "            img = img.numpy()\n",
    "            new_img = []\n",
    "            for i in range(img.shape[2]):\n",
    "                new_img.append(img[:,:,i])\n",
    "            x_out.append(new_img)\n",
    "            y_out.append(label)\n",
    "    return x_out, y_out       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Using 1600 files for training.\n",
      "Using 400 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"../datasets/data3\", # путь к изображениям\n",
    "    validation_split=0.2, # процент на тест\n",
    "    subset=\"both\", # берем и обучающую и тестовую выборку\n",
    "    seed=42, # сид генератора случайных чисел\n",
    "    image_size=(32,32), # целевой размер изображения (СНАЧАЛА ВЫСОТА, ПОТОМ ШИРИНА)\n",
    "    batch_size=32, # размер пакета (батча)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 89.21875 ,  63.609375, 101.765625, ..., 107.5     , 107.25    ,\n",
      "        110.65625 ],\n",
      "       [104.609375, 151.82812 , 106.34375 , ..., 136.625   ,  96.609375,\n",
      "        105.28125 ],\n",
      "       [106.015625, 106.375   ,  91.625   , ...,  71.90625 , 118.1875  ,\n",
      "        110.65625 ],\n",
      "       ...,\n",
      "       [249.95312 , 245.84375 , 116.453125, ..., 120.8125  , 124.75    ,\n",
      "        124.390625],\n",
      "       [245.25    , 250.5     , 254.4375  , ..., 112.75    , 122.      ,\n",
      "        119.1875  ],\n",
      "       [255.      , 255.      , 255.      , ..., 112.578125, 112.953125,\n",
      "        117.828125]], dtype=float32), array([[ 90.21875 ,  72.203125, 104.109375, ..., 105.71875 , 100.265625,\n",
      "        111.65625 ],\n",
      "       [101.609375, 153.14062 , 101.5     , ..., 126.453125,  97.609375,\n",
      "        107.28125 ],\n",
      "       [103.0625  , 105.375   ,  89.625   , ...,  64.90625 , 117.1875  ,\n",
      "        102.796875],\n",
      "       ...,\n",
      "       [255.      , 255.      , 129.04688 , ..., 121.8125  , 125.75    ,\n",
      "        127.140625],\n",
      "       [255.      , 255.      , 253.42188 , ..., 113.75    , 123.      ,\n",
      "        121.9375  ],\n",
      "       [255.      , 255.      , 255.      , ..., 115.4375  , 116.75    ,\n",
      "        124.828125]], dtype=float32), array([[ 75.71875 ,  67.546875,  98.609375, ...,  86.203125,  90.328125,\n",
      "         93.65625 ],\n",
      "       [ 85.765625, 158.84375 , 100.921875, ..., 113.46875 ,  84.609375,\n",
      "         86.03125 ],\n",
      "       [ 93.921875, 101.375   ,  91.125   , ...,  48.90625 ,  97.140625,\n",
      "        100.75    ],\n",
      "       ...,\n",
      "       [251.      , 254.98438 , 134.96875 , ..., 107.8125  , 111.75    ,\n",
      "        110.890625],\n",
      "       [255.      , 252.25    , 255.      , ...,  99.75    , 109.      ,\n",
      "        105.6875  ],\n",
      "       [255.      , 255.      , 255.      , ..., 104.4375  , 103.359375,\n",
      "        107.328125]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "X, y = predobrab_data(train_ds)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "89a5f16f55e2de052578cff55a885ce93a3c0921933ea9c745181d82db8606d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
