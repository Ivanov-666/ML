{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import re\n",
        "from pymorphy3 import MorphAnalyzer\n",
        "from nltk.corpus import stopwords\n",
        "from razdel import tokenize\n",
        "from navec import Navec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device ( \"cuda:0\" if torch.cuda.is_available() else \"cpu\" )\n",
        "print ( device )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "HplNyq17OG_X",
        "outputId": "655f84cf-5af8-42b4-e383-085f2901eeb0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>public_petition_text</th>\n",
              "      <th>reason_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1638</th>\n",
              "      <td>3315301</td>\n",
              "      <td>На газоне разбросан различный мусор. \\nПросьба...</td>\n",
              "      <td>Благоустройство</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53659</th>\n",
              "      <td>3372310</td>\n",
              "      <td>Конструкции, препятствующие парковке</td>\n",
              "      <td>Благоустройство</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25910</th>\n",
              "      <td>3294518</td>\n",
              "      <td>Лестницу убирают раз в три месяца и просто выл...</td>\n",
              "      <td>Содержание МКД</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52453</th>\n",
              "      <td>3158213</td>\n",
              "      <td>мусор с задней стороны дома</td>\n",
              "      <td>Благоустройство</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12590</th>\n",
              "      <td>3356661</td>\n",
              "      <td>Снова не работает уличный фонарь у входной две...</td>\n",
              "      <td>Содержание МКД</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33876</th>\n",
              "      <td>3084944</td>\n",
              "      <td>Убрать листву с газона.</td>\n",
              "      <td>Благоустройство</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6550</th>\n",
              "      <td>3344824</td>\n",
              "      <td>При входе в первый подъезд на первом этаже ест...</td>\n",
              "      <td>Содержание МКД</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16469</th>\n",
              "      <td>3079420</td>\n",
              "      <td>Прошу убрать резиновые покрышки, которые в соо...</td>\n",
              "      <td>Благоустройство</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35789</th>\n",
              "      <td>2964425</td>\n",
              "      <td>Мусор возле магазина магнит</td>\n",
              "      <td>Благоустройство</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44639</th>\n",
              "      <td>2980756</td>\n",
              "      <td>1 парадная, требуется отремонтировать доводчик</td>\n",
              "      <td>Содержание МКД</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id                               public_petition_text   \n",
              "1638   3315301  На газоне разбросан различный мусор. \\nПросьба...  \\\n",
              "53659  3372310               Конструкции, препятствующие парковке   \n",
              "25910  3294518  Лестницу убирают раз в три месяца и просто выл...   \n",
              "52453  3158213                        мусор с задней стороны дома   \n",
              "12590  3356661  Снова не работает уличный фонарь у входной две...   \n",
              "...        ...                                                ...   \n",
              "33876  3084944                            Убрать листву с газона.   \n",
              "6550   3344824  При входе в первый подъезд на первом этаже ест...   \n",
              "16469  3079420  Прошу убрать резиновые покрышки, которые в соо...   \n",
              "35789  2964425                        Мусор возле магазина магнит   \n",
              "44639  2980756     1 парадная, требуется отремонтировать доводчик   \n",
              "\n",
              "       reason_category  \n",
              "1638   Благоустройство  \n",
              "53659  Благоустройство  \n",
              "25910   Содержание МКД  \n",
              "52453  Благоустройство  \n",
              "12590   Содержание МКД  \n",
              "...                ...  \n",
              "33876  Благоустройство  \n",
              "6550    Содержание МКД  \n",
              "16469  Благоустройство  \n",
              "35789  Благоустройство  \n",
              "44639   Содержание МКД  \n",
              "\n",
              "[10000 rows x 3 columns]"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"../datasets/Petitions.csv\")\n",
        "corpus = df.sample(10000, random_state=42)\n",
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ham_sq84OOyI",
        "outputId": "5acf6d1a-d2d2-424b-9b4c-d86f31f3b074"
      },
      "outputs": [],
      "source": [
        "corpus_text = corpus[\"public_petition_text\"]\n",
        "corpus_text_category = corpus[\"reason_category\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "kXOB8qkfPOD3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1638     На газоне разбросан различный мусор. \\nПросьба...\n",
            "53659                 Конструкции, препятствующие парковке\n",
            "25910    Лестницу убирают раз в три месяца и просто выл...\n",
            "52453                          мусор с задней стороны дома\n",
            "12590    Снова не работает уличный фонарь у входной две...\n",
            "                               ...                        \n",
            "33876                              Убрать листву с газона.\n",
            "6550     При входе в первый подъезд на первом этаже ест...\n",
            "16469    Прошу убрать резиновые покрышки, которые в соо...\n",
            "35789                          Мусор возле магазина магнит\n",
            "44639       1 парадная, требуется отремонтировать доводчик\n",
            "Name: public_petition_text, Length: 10000, dtype: object\n",
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "print(corpus_text)\n",
        "print(type(corpus_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'Благоустройство',\n",
              " 1: 'Водоотведение',\n",
              " 2: 'Водоснабжение',\n",
              " 3: 'Кровля',\n",
              " 4: 'Нарушение порядка пользования общим имуществом',\n",
              " 5: 'Нарушение правил пользования общим имуществом',\n",
              " 6: 'Незаконная информационная и (или) рекламная конструкция',\n",
              " 7: 'Незаконная реализация товаров с торгового оборудования (прилавок, ящик, с земли)',\n",
              " 8: 'Повреждения или неисправность элементов уличной инфраструктуры',\n",
              " 9: 'Подвалы',\n",
              " 10: 'Санитарное состояние',\n",
              " 11: 'Содержание МКД',\n",
              " 12: 'Состояние рекламных или информационных конструкций',\n",
              " 13: 'Фасад',\n",
              " 14: 'Центральное отопление'}"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "le = LabelEncoder()\n",
        "corpus_text_category_encoded = le.fit_transform(corpus_text_category)\n",
        "dict(zip(range(0, len(set(corpus_text_category_encoded))),le.inverse_transform(list(set(corpus_text_category_encoded)))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus_encoded = []\n",
        "for i in range(len(corpus_text)):\n",
        "    corpus_encoded.append((corpus_text.iloc[i], corpus_text_category_encoded[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "navec = Navec.load('../models/navec_hudlit_v1_12B_500K_300d_100q.tar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "Nqkfy_egmVRW"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "def prepare_data(corpus):\n",
        "    morph = MorphAnalyzer()\n",
        "    from nltk.corpus import stopwords\n",
        "    stopwords = stopwords.words('russian')\n",
        "    prepared_data = []\n",
        "    for petition, label in corpus:   \n",
        "        data = petition.lower()\n",
        "        data1 = re.sub('[\\\\r|\\\\n]+', ' ', data)\n",
        "        data2 = re.sub('[a-zA-Z]+', '', data1)\n",
        "        data3 = re.sub('[0-9]+', '', data2)\n",
        "        data4 = re.sub('[^\\s^\\w]+', '', data3)\n",
        "        data5 = list(tokenize(data4))\n",
        "        data6 = map(lambda x: x.text , data5)\n",
        "        data7 = map(lambda x: morph.normal_forms(x)[0], data6)\n",
        "        data8 = [w for w in data7 if w not in stopwords]\n",
        "        data9 = [navec[x].tolist() for x in data8 if x in navec]\n",
        "        if(len(data9)):\n",
        "            prepared_data.append((torch.tensor(data9).type(torch.float32), label))\n",
        "    return prepared_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "YtvoLM4_q5pW"
      },
      "outputs": [],
      "source": [
        "corpus_text_prep = prepare_data(corpus_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "corpus_text_padded = pad_sequence([tupl[0] for tupl in corpus_text_prep], True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([9965, 229, 300])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus_text_padded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(corpus_text_padded, [tupl[1] for tupl in corpus_text_prep], test_size=0.1, stratify=[tupl[1] for tupl in corpus_text_prep])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds = TensorDataset(X_train, torch.tensor(y_train).type(torch.int64))\n",
        "dl = DataLoader(ds, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Rnn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Rnn, self).__init__()\n",
        "        self.rnn = nn.RNN(300, 128, batch_first=True)\n",
        "        self.first_linear = nn.Linear(128, 15)\n",
        "    def forward(self, x):\n",
        "        y = self.rnn(x)[1]\n",
        "        #y = self.first_linear(torch.index_select(y, 1, torch.tensor(y.shape[1]-1).to(device)))\n",
        "        y = self.first_linear(y[-1])\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "model = Rnn()\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха 1, Значение функции потерь: 1.4274958372116089\n",
            "Эпоха 2, Значение функции потерь: 1.575461983680725\n",
            "Эпоха 3, Значение функции потерь: 1.4686797857284546\n",
            "Эпоха 4, Значение функции потерь: 1.3945531845092773\n",
            "Эпоха 5, Значение функции потерь: 1.3837037086486816\n",
            "Эпоха 6, Значение функции потерь: 1.379629373550415\n",
            "Эпоха 7, Значение функции потерь: 1.3802326917648315\n",
            "Эпоха 8, Значение функции потерь: 1.3870748281478882\n",
            "Эпоха 9, Значение функции потерь: 1.3860352039337158\n",
            "Эпоха 10, Значение функции потерь: 1.3816720247268677\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    sum_loss = 0\n",
        "    for x_b, y_b in dl:\n",
        "        x_b = x_b.to(device)\n",
        "        y_b = y_b.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x_b)\n",
        "        #outputs= outputs.view(x_b.shape[0],15)\n",
        "        loss_value = loss(outputs, y_b)\n",
        "        sum_loss += loss_value\n",
        "        loss_value.backward()\n",
        "        optimizer.step()\n",
        "        x_b = x_b.to(\"cpu\")\n",
        "        y_b = y_b.to(\"cpu\")\n",
        "        \n",
        "        #sys.stderr.write(f'Батч {batch + 1}/{len(dl)}, Значение функции потерь: {loss_value.item()}\\r')\n",
        "\n",
        "    print(f'Эпоха {epoch + 1}, Значение функции потерь: {sum_loss/len(dl)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.to(\"cpu\")\n",
        "answ = model.forward(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "answ_encoded = []\n",
        "for i in answ:\n",
        "    answ_encoded.append(torch.argmax(i).to(\"cpu\").item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.97      0.73       582\n",
            "           1       0.00      0.00      0.00         4\n",
            "           2       0.00      0.00      0.00        13\n",
            "           3       0.00      0.00      0.00        15\n",
            "           4       0.00      0.00      0.00         4\n",
            "           5       0.00      0.00      0.00        32\n",
            "           6       0.00      0.00      0.00        32\n",
            "           7       0.00      0.00      0.00         4\n",
            "           8       0.00      0.00      0.00        19\n",
            "           9       0.00      0.00      0.00         4\n",
            "          10       0.00      0.00      0.00         7\n",
            "          11       0.39      0.05      0.09       241\n",
            "          12       0.00      0.00      0.00        12\n",
            "          13       0.00      0.00      0.00        23\n",
            "          14       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.58       997\n",
            "   macro avg       0.07      0.07      0.06       997\n",
            "weighted avg       0.44      0.58      0.45       997\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\XE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\XE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\XE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, answ_encoded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.rnn = nn.LSTM(300, 64, batch_first = True)\n",
        "        self.first_linear = nn.Linear(64, 15)\n",
        "        #self.first_linear = nn.Linear(64, 32)\n",
        "        #self.first_activ = nn.LeakyReLU()\n",
        "        #self.second_linear = nn.Linear(32, 15)\n",
        "    def forward(self, x):\n",
        "        y = self.rnn(x)[1]\n",
        "        #y = self.first_linear(torch.index_select(y, 1, torch.tensor(y.shape[1]-1).to(device)))\n",
        "        y = self.first_linear(y[-1])\n",
        "        #y = self.first_activ(y)\n",
        "        #y = self.second_linear(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss1 = nn.CrossEntropyLoss()\n",
        "model1 = LSTM()\n",
        "model1.to(device)\n",
        "optimizer1 = torch.optim.Adam(model.parameters(), lr=0.0025)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха 1, Значение функции потерь: 2.654219388961792\n",
            "Эпоха 2, Значение функции потерь: 2.6541669368743896\n",
            "Эпоха 3, Значение функции потерь: 2.6542744636535645\n",
            "Эпоха 4, Значение функции потерь: 2.6542510986328125\n",
            "Эпоха 5, Значение функции потерь: 2.6542344093322754\n",
            "Эпоха 6, Значение функции потерь: 2.654247999191284\n",
            "Эпоха 7, Значение функции потерь: 2.654240846633911\n",
            "Эпоха 8, Значение функции потерь: 2.6542809009552\n",
            "Эпоха 9, Значение функции потерь: 2.6542749404907227\n",
            "Эпоха 10, Значение функции потерь: 2.654237985610962\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    sum_loss = 0\n",
        "    for x_b, y_b in dl:\n",
        "        x_b = x_b.to(device)\n",
        "        y_b = y_b.to(device)\n",
        "        optimizer1.zero_grad()\n",
        "        outputs = model1(x_b)\n",
        "        outputs= outputs.view(x_b.shape[0],15)\n",
        "        loss_value = loss1(outputs, y_b)\n",
        "        loss_value.backward()\n",
        "        optimizer1.step()\n",
        "        sum_loss += loss_value\n",
        "        x_b = x_b.to(\"cpu\")\n",
        "        y_b = y_b.to(\"cpu\")\n",
        "        \n",
        "        #sys.stderr.write(f'Батч {batch + 1}/{len(dl)}, Значение функции потерь: {loss_value.item()}\\r')\n",
        "\n",
        "    print(f'Эпоха {epoch + 1}, Значение функции потерь: {sum_loss/len(dl)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "[enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 3330084864 bytes.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mf:\\ML\\notebooks\\Лр2_NLP.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/ML/notebooks/%D0%9B%D1%802_NLP.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model1\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/ML/notebooks/%D0%9B%D1%802_NLP.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m answ1 \u001b[39m=\u001b[39m model1\u001b[39m.\u001b[39;49mforward(X_test)\n",
            "\u001b[1;32mf:\\ML\\notebooks\\Лр2_NLP.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/ML/notebooks/%D0%9B%D1%802_NLP.ipynb#X34sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/ML/notebooks/%D0%9B%D1%802_NLP.ipynb#X34sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn(x)[\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML/notebooks/%D0%9B%D1%802_NLP.ipynb#X34sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m#y = self.first_linear(torch.index_select(y, 1, torch.tensor(y.shape[1]-1).to(device)))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/ML/notebooks/%D0%9B%D1%802_NLP.ipynb#X34sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirst_linear(y[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
            "File \u001b[1;32mc:\\Users\\XE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\XE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    811\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 812\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    813\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    814\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    815\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    816\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 3330084864 bytes."
          ]
        }
      ],
      "source": [
        "model1.to(\"cpu\")\n",
        "answ1 = model1.forward(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "answ_encoded1 = []\n",
        "for i in answ1:\n",
        "    answ_encoded1.append(torch.argmax(i).item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [997, 1]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mf:\\ML\\notebooks\\Лр2_NLP.ipynb Cell 27\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/ML/notebooks/%D0%9B%D1%802_NLP.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m classification_report\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/ML/notebooks/%D0%9B%D1%802_NLP.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(classification_report(y_test, answ_encoded1))\n",
            "File \u001b[1;32mc:\\Users\\XE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2310\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclassification_report\u001b[39m(\n\u001b[0;32m   2196\u001b[0m     y_true,\n\u001b[0;32m   2197\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2204\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2205\u001b[0m ):\n\u001b[0;32m   2206\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[0;32m   2207\u001b[0m \n\u001b[0;32m   2208\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2307\u001b[0m \u001b[39m    <BLANKLINE>\u001b[39;00m\n\u001b[0;32m   2308\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2310\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   2312\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2313\u001b[0m         labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\n",
            "File \u001b[1;32mc:\\Users\\XE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     60\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[0;32m     62\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m     87\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\XE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [997, 1]"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, answ_encoded1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GRU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GRU, self).__init__()\n",
        "        self.rnn = nn.GRU(300, 64, batch_first = True)\n",
        "        self.first_linear = nn.Linear(64, 15)\n",
        "        #self.first_linear = nn.Linear(64, 32)\n",
        "        #self.first_activ = nn.LeakyReLU()\n",
        "        #self.second_linear = nn.Linear(32, 15)\n",
        "    def forward(self, x):\n",
        "        y = self.rnn(x)[1]\n",
        "        #y = self.first_linear(torch.index_select(y, 1, torch.tensor(y.shape[1]-1).to(device)))\n",
        "        y = self.first_linear(y[-1])\n",
        "        #y = self.first_activ(y)\n",
        "        #y = self.second_linear(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss2 = nn.CrossEntropyLoss()\n",
        "model2 = GRU()\n",
        "model2.to(device)\n",
        "optimizer2 = torch.optim.Adam(model.parameters(), lr=0.0025)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха 1, Значение функции потерь: 2.737246513366699\n",
            "Эпоха 2, Значение функции потерь: 2.7423622608184814\n",
            "Эпоха 3, Значение функции потерь: 2.7218260765075684\n",
            "Эпоха 4, Значение функции потерь: 2.757697820663452\n",
            "Эпоха 5, Значение функции потерь: 2.802489995956421\n",
            "Эпоха 6, Значение функции потерь: 2.750302791595459\n",
            "Эпоха 7, Значение функции потерь: 2.762470006942749\n",
            "Эпоха 8, Значение функции потерь: 2.775080919265747\n",
            "Эпоха 9, Значение функции потерь: 2.7875592708587646\n",
            "Эпоха 10, Значение функции потерь: 2.757697820663452\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    batch = 0\n",
        "    for x_b, y_b in dl:\n",
        "        x_b = x_b.to(device)\n",
        "        y_b = y_b.to(device)\n",
        "        optimizer2.zero_grad()\n",
        "        batch+=1\n",
        "        outputs = model2(x_b)\n",
        "        #outputs= outputs.view(x_b.shape[0],15)\n",
        "        loss_value = loss2(outputs, y_b)\n",
        "        loss_value.backward()\n",
        "        \n",
        "        optimizer2.step()\n",
        "        \n",
        "        #sys.stderr.write(f'Батч {batch + 1}/{len(dl)}, Значение функции потерь: {loss_value.item()}\\r')\n",
        "\n",
        "    print(f'Эпоха {epoch + 1}, Значение функции потерь: {loss_value.item()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       582\n",
            "           1       0.00      0.00      0.00         4\n",
            "           2       0.00      0.00      0.00        13\n",
            "           3       0.00      0.00      0.00        15\n",
            "           4       0.00      0.00      0.00         4\n",
            "           5       0.00      0.00      0.00        32\n",
            "           6       0.00      0.00      0.00        32\n",
            "           7       0.00      0.00      0.00         4\n",
            "           8       0.00      0.00      0.00        19\n",
            "           9       0.00      0.00      0.00         4\n",
            "          10       0.01      1.00      0.01         7\n",
            "          11       0.00      0.00      0.00       241\n",
            "          12       0.00      0.00      0.00        12\n",
            "          13       0.00      0.00      0.00        23\n",
            "          14       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.01       997\n",
            "   macro avg       0.00      0.07      0.00       997\n",
            "weighted avg       0.00      0.01      0.00       997\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\XE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\XE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\XE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "answ2 = model2.forward(X_test.to(device))\n",
        "answ_encoded2 = []\n",
        "for i in answ2:\n",
        "    answ_encoded2.append(torch.argmax(i).to(\"cpu\").item())\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, answ_encoded2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
