# Демо экзамен

## Предобработка
1. Анализируем сами данные, пердметную область, размерности, какие колонки что значат.
1. Смотрим количество пропусков, насколько их много и в каких столбцах(df.describe(здесь по квартилям проверяем на выбросы сразу), df.info).
1. Пытаемся удалить повторы и столбцы с id.
1. Строим графики: распределение всех столбцов(df.hist(bins=10, figsize=(25, 20))), хитмап(df_num = df[numeric_cols].dropna() ax, fig = plt.subplots(figsize=[16,9]) sns.heatmap(df_num.corr(),  annot=True)), зависимость всех столбцов от целеого(fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(15, 10)) for idx, feature in enumerate(df.columns[:-1]): df.plot(feature, "cnt", subplots=True, kind="scatter",ax=axes[idx // 4, idx % 4])).
1. Разбиваем признаки на числовые, категориальные, делаем под них списки с именами.

### Числовые
> Смотрим количество уникальных значений в каждом, возомжно некоторые стоит переместить в категриальные.
> Заполняем средним либо нулями, одновременно проверяя гистограмму распределения, если что строим модель под заполнение, исходя из признаков которые хорошо коллерируют с нашим.

### Категориальные
Оцениваем отдельно каждый столбец
> Заполняем модой \
> Если признак бинарный, смотрим уникальные и делаем one-hot\
> Если признак многозначный, но конечный, смотрим уникальные делаем one-hot либо кодируем чилами\
> Если признак бесокнечнозначный делаем ван хот без проверок на мусор

### Гиперкоррелированность
> Строим heatmap, по нему смотрим гиперкоррелированные признаки, если они есть, удаляем, т.к. они будут мешать обучению, проверить что они мешают можно через lasso regression.

### Масштабирование
> Выбираем Standardscaler если распределение всех столбцов нормальное или MinMaxScaler чтобы сохранить изначальное распределение. Сначала делим данные, после масштабируем тестовую и тренировочную выборки

### Оверсемплинг
>Применяем только лишь на трейне.

## Моделирование
1. Сразу посмотреть размерность датасета и подготовиться морально, будут ли долго учиться модели, если что сразу отколоть кусок от данных на подбор гиперпараметров и кроссс-валидацию.

## Ссылки
>https://github.com/Ivanov-666/ML
>https://github.com/IamVOC/MLBasics\
>https://pseudocoder.ru/ml-labs